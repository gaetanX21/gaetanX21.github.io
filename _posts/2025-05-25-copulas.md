---
layout: post
title: "Copula Theory and the Subprime Mortgage Crisis"
date: 2025-05-25
description: "TL;DR: Copulas are a powerful tool for modeling the correlation structure between random variables. We propose an intuition-first introduction to copula theory, culminating in a discussion of the role of copulas in the 2008 subprime mortgage crisis."
tags: probability-theory, statistics, extreme-value-theory
thumbnail: assets/img/posts/copulas/clayton.png
---

$$
\newcommand{\R}{\mathbb{R}}
\newcommand{\tn}[1]{\textnormal{#1}}
\newcommand{\L}{\mathcal{L}}
\newcommand{\P}{\mathbb{P}}
$$

In this post, we will explore the concept of copulas, which are mathematical functions that allow us to model the correlation structure between random variables. After a lightning-fast introduction to copula theory, we will visualize some important copulas to get an intuitive understanding of their behavior. After discussing the concept of tail dependence and how it can be quantified, we will see how different copulas capture tail dependence in different ways. Finally, we will discuss the role of copulas in the subprime mortgage crisis, where they were used to model the correlation structure of mortgage-backed securities, leading to a catastrophic underestimation of risk.

---

<div class="row justify-content-center" id="fig-1">
    <div class="col-sm-6 mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/copulas/clayton.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 1. Clayton copula with $\theta=1$. The bright area in the lower left corner indicates lower tail dependence, as we will see later.
</div>

## I. Motivation

Consider the following problem:

> You are given two random variables $X\sim \L_X$ and $Y\sim \L_Y$ where $\L_X$ and $\L_Y$ are known and you want to model their correlation structure.

As you can imagine, this type of problem shows up rather quickly whenever we want to finely model the interactions between two or more random variables.
In practice, we often circumvent this problem by working under one of the following (strong) assumptions:
1. **Independence**: We assume that $X$ and $Y$ are independent, which means that their joint distribution can be expressed as the product of their marginal distributions: $\L_{XY} = \L_X \otimes \L_Y$.
2. **Multivariate normality**: We assume that $(X,Y)$ follows a bivariate normal distribution, which allows us to model their correlation structure with a covariance matrix.

While these two assumptions are quite convenient and can still be useful to build simple models, in practice they are often too restrictive and do not capture the true nature of the relationship between $X$ and $Y$.

For instance, if you are insuring houses in *several* nearby flood-prone areas, you might want to use Gumbel distributions to model the *marginal* distributions of the flood levels in each separate area, but you would still need to model the *joint* distribution of the cross-area flood levels to assess the risk of a catastrophic event affecting multiple areas at once (and potentially leading to bankruptcy of your insurance company!).

Lucky for us, probability theory has got exactly the tool we are looking for: **copula theory**.

## II. Quick introduction to copulas

In this section, I'll give a quick and intuition-first introduction to copulas, which will be enough to understand the rest of the post. For a more in-depth introduction, there are many great resources available online[^blog]. I'll skip the scary and technical definition of a copula and instead focus on the **intuition** behind it! I will limit myself to the bivariate case, but the generalization to more than two variables is straightforward (I promise!).

Let's again consider $X$, $Y$ two random variables with known marginal distributions $\L_X$ and $\L_Y$. We are looking for a *well-behaved mathematical object* to encode the correlation structure between $X$ and $Y$. One natural candidate is the **joint cumulative distribution function**

$$
F_{XY}(x,y) = P(X \leq x, Y \leq y)
$$

The problem with this object is that its domain $\mathcal{D}(F_{XY}) = \mathcal{X} \times \mathcal{Y}$ depends on $X$ and $Y$.

There's a neat trick to get around this: we can use the **probability integral transform** to map both $X$ and $Y$ to the unit interval $[0,1]$. To do so, let:

$$
(U,V) = \big(F_X(X), F_Y(Y)\big)
$$

Notice that $U$ and $V$ are both uniformly distributed on $[0,1]$, by property of the probability integral transform. Crucially, the joint distribution of $(U,V)$ **still encodes the correlation structure between $X$ and $Y$**, but now it is defined on the fixed domain $\mathcal{D}(U,V) = [0,1]^2$.

We can now define the **joint cumulative distribution function of $(U,V)$** as:

$$
C_{XY}(u,v) = \P(U \leq u, V \leq v) = \P(F_X(X) \leq u, F_Y(Y) \leq v) = \P(X \leq F_X^{-1}(u), Y \leq F_Y^{-1}(v))
$$

This function $C_{XY}(u,v)$ is called a **copula**, and it captures the joint distribution of the random variables $X$ and $Y$ while being defined on a fixed domain. The key property of copulas is that they allow us to separate the marginal distributions from the correlation structure, which is precisely what we need to model the relationship between $X$ and $Y$.

We can sum up what we just saw as follows:

> The joint distribution of two random variables $X$ and $Y$ can split into two components: the marginal distributions $\L_X$ and $\L_Y$, and the copula $C_{XY}$ that captures the correlation structure between them.

The above result is known as **Sklar's theorem**, and it actually works both ways: you can split any multivariate distribution into its marginals and a copula, but if you're given some marginals and a copula, you can also construct the corresponding multivariate distribution!


<div class="row justify-content-center" id="fig-2">
    <div class="col-sm-6 mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/copulas/sklar.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 2. Sklar's theorem in a nutshell: a multivariate distribution can be decomposed into its marginals and a copula; conversely, given marginals and a copula, we can reconstruct the corresponding multivariate distribution.
</div>

Given the above intuitive definition, it should be clear that a (bivariate) copula is formally defined as a function

$$C: [0,1]^2 \to [0,1]$$

> As such, we can conveniently represent it as a 2D surface in the unit square, where the height of the surface at a point $(u,v)$ corresponds to the value of the copula $C(u,v)$. This will be useful later when we visualize some important copulas.

With this in mind, we can move on to the next section, where we will explore some important copulas and their properties.

## III. Important copulas

### A. Gaussian copula

As usual in statistics, the Gaussian case will be the easiest to understand and manipulate. For a given correlation matrix
$$
\Sigma_\rho = \begin{pmatrix} 1 & \rho \\ \rho & 1 \end{pmatrix}
$$

the Gaussian copula is defined as:

$$
C_{\rho}^\tn{Gauss}(u,v) = \Phi_\rho(\Phi^{-1}(u), \Phi^{-1}(v))
$$

where $\Phi$ is the cumulative distribution function of the standard normal distribution, and $\Phi_\rho$ is the cumulative distribution function for $\mathcal{N}(0,\Sigma_\rho)$. The Gaussian copula is particularly useful because it allows us to model the correlation structure between two random variables using a single parameter $\rho$, which is the correlation coefficient.

Below is a plot of the Gaussian copula for $\rho=0.5$.

<div class="row justify-content-center" id="fig-3">
    <div class="col-sm-6 mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/copulas/gaussian.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 3. Gaussian copula with $\rho=0.5$.
</div>

### B. Student copula

As we shall see in the next section, the Gaussian copula has bad tail properties: it does not capture the tail dependence between the random variables $X$ and $Y$. One alternative is the **Student copula**, which is defined in a similar fashion as the Gaussian copula, but uses the Student's t-distribution instead of the normal distribution. The Student copula is parameterized by the degrees of freedom $\nu$ and the correlation matrix $\Sigma_\rho$. It is defined as:

$$
C_{\rho,\nu}^\tn{Student}(u,v) = t_{\rho,\nu}(t_\nu^{-1}(u), t_\nu^{-1}(v))
$$

where $t_\nu$ is the cumulative distribution function of the Student's t-distribution with $\nu$ degrees of freedom, and $t_{\rho,\nu}$ is the cumulative distribution function for the bivariate Student's t-distribution with correlation $\rho$ and $\nu$ degrees of freedom. The Student copula is particularly useful when we want to model tail dependence, as it allows for heavier tails than the Gaussian copula.

Below is a plot of the Student copula for $\rho=0.5$ and $\nu=1$.

<div class="row justify-content-center" id="fig-4">
    <div class="col-sm-6 mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/copulas/student.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 4. Student copula with $\rho=0.5$ and $\nu=1$.
</div>

As you can see, correlation increases at the tails compared to the Gaussian copula, which is a key property of the Student copula. Don't worry if this doesn't make sense yet, we'll come back to this in the next section when we discuss tail dependence.

### C. Gumbel copula

We've seen that unlike the Gaussian copula, the Student copula captures tail dependence, but it does so in a *symmetric* way: correlation at the upper (near $(1,1)$) and lower (near $(0,0)$) tails is the same. In practice however, it is often the case that the correlation structure is *asymmetric*. If we model floods for instance, we expect the upper tail (high flood levels) to be more correlated than the lower tail (low flood levels), since floods are often caused by extreme weather events that affect multiple areas at once. In such cases, we need a copula that can capture upper tail dependence.

Turns out that the Gumbel copula does exactly that. To avoid scaring you and because it wouldn't add much to the discussion, I won't give the analytic definition of the Gumbel copula, but rather give you a feeling of how it behaves through its graphical representation, which is shown below for $\theta=2$ (the parameter $\theta$ controls the strength of the upper tail dependence).

<div class="row justify-content-center" id="fig-5">
    <div class="col-sm-6 mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/copulas/gumbel.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 5. Gumbel copula with $\theta=2$.
</div>

As you can see, the Gumbel copula captures upper tail dependence, which means that the correlation between $X$ and $Y$ increases as we approach the upper right corner $(1,1)$. As said before, this is particularly useful when modeling extreme climatic events such as floods, earthquakes or fires, where we know that catastrophic events can create strong correlation at the upper tail.

### D. Clayton copula

Just like the Gumbel copula captures upper tail dependence, the **Clayton copula** captures lower tail dependence. Again, there's no need to mull over the analytic definition, so let's just look at the graphical representation of the Clayton copula for $\theta=1$ and see if we can get a feeling for how it behaves.

<div class="row justify-content-center" id="fig-6">
    <div class="col-sm-6 mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/copulas/clayton.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 6. Clayton copula with $\theta=1$.
</div>

We see that just like the Gumbel copula captures upper tail dependence, the Clayton copula captures lower tail dependence, which means that the correlation between $X$ and $Y$ increases as we approach the lower left corner $(0,0)$. This is particularly useful when modeling financial data, where losses are often more correlated than gains due to market-wide events such as economic downturns or financial crises.

### E. Summary
In summary, we have seen four important copulas: Gaussian, Student, Gumbel and Clayton. Each of these copulas has its own properties and is useful in different contexts as we shall see in the next section. Below is the four copulas visualized together for comparison:
<div class="row justify-content-center" id="fig-7">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/copulas/gaussian.png" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/copulas/student.png" class="img-fluid rounded z-depth-1" %}
    </div> 
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/copulas/gumbel.png" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/copulas/clayton.png" class="img-fluid rounded z-depth-1" %}
    </div> 
</div>
<div class="caption">
    Figure 7. Comparison of the four copulas: Gaussian, Student, Gumbel and Clayton.
</div>

## IV. Tail dependence

The goal of this section is to give you a feeling for what tail dependence is and why it matters. To do so, we will first informally define the concept of tail dependence, then we will see how it can be quantified using the concept of **tail dependence coefficient**, and finally we will see how different copulas capture tail dependence in different ways.

### A. An informal definition of tail dependence

Informally, tail dependence refers to the correlation between two random variables **in the extreme tails of their distributions**. Notice that there are two tails (lower and upper), so we have to distinguish between lower tail dependence (correlation in the lower tail) and upper tail dependence (correlation in the upper tail):
- **Lower tail dependence**: think of it as $\P(\tn{Y goes to its lower tail} \mid \tn{X is at its lower tail})$, i.e. the probability that $Y$ takes on an extremely low value given that $X$ is at an extremely low value.
- **Upper tail dependence**: think of it as $\P(\tn{Y goes to its upper tail} \mid \tn{X is at its upper tail})$, i.e. the probability that $Y$ takes on an extremely high value given that $X$ is at an extremely high value.


### B. The tail dependence coefficient

Let's now take the above two definitions and formalize them a bit. We can define the **lower tail dependence coefficient** $\lambda_L$ and the **upper tail dependence coefficient** $\lambda_U$ as follows:

$$
\lambda_L = \lim_{u \searrow 0} \P(Y \leq F_Y^{-1}(u) \mid X \leq F_X^{-1}(u))
$$

and

$$
\lambda_U = \lim_{u \nearrow 1} \P(Y \geq F_Y^{-1}(u) \mid X \geq F_X^{-1}(u))
$$

These coefficients measure the strength of the tail dependence between $X$ and $Y$. If $\lambda_L > 0$ (resp. $\lambda_U > 0$), then there **is** lower (resp. upper) tail dependence. If the coefficients are zero, then there is **no** tail dependence.

Intuitively, it should make sense to you that **having no tail dependence is generally bad for modeling**. If we go back to our example of insuring houses in flood-prone areas, and $X$ (resp. $Y$) is the flood level in area A (resp. B), then having no tail dependence means that a flood in one area does not increase the probability of a flood in the other area, which is not what we would expect in practice. On the other hand, having tail dependence means that if a flood occurs in one area, it is more likely that a flood will occur in the other area as well, which is exactly what we want to capture! Likewise, if $X$ (resp. $Y$) is risk of default for company A (resp. B), then having no tail dependence means that a default in one company does not increase the probability of a default in the other company, which we know simply isn't true in practice. More on that in the next section!

### C. How different copulas capture tail dependence
Now that we have a good understanding of what tail dependence is and how it can be quantified, let's compare the tail dependence coefficients of the four copulas we introduced earlier. This will nicely complement the intuition we got from their graphical representations in the previous section. Once again, I won't go into the derivations of these coefficients as it wouldn't add much to the discussion!

<div style="text-align: center;">
  <table border="2" style="margin: 0 auto; border-collapse: collapse;">
    <caption style="caption-side: bottom; text-align: center; margin-top: 8px;">
      Table 1: Tail dependence coefficients for various copulas.
    </caption>
    <thead>
      <tr>
        <th>Copula</th>
        <th>λ<sub>L</sub></th>
        <th>λ<sub>U</sub></th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Gaussian</td>
        <td>0</td>
        <td>0</td>
      </tr>
      <tr>
        <td>Student-t</td>
        <td>&gt; 0 (depends on $\nu$)</td>
        <td>&gt; 0 (depends on $\nu$)</td>
      </tr>
      <tr>
        <td>Gumbel</td>
        <td>0</td>
        <td>2 - 2<sup>1/θ</sup></td>
      </tr>
      <tr>
        <td>Clayton</td>
        <td>2<sup>-1/θ</sup></td>
        <td>0</td>
      </tr>
    </tbody>
  </table>
</div>

<br>

## V. The subprime mortgage crisis 

At this stage you might start having an idea of the link between copulas and the subprime mortgage crisis.
Here is a (very) brief recap of what you need to know:
1. From an individual's point of view, a mortgage is a loan taken out to buy their house. From a bank's point of view, a mortgage is an **asset that generates interest payments**, albeit with some risk of default.
2. Because individual mortgages aren't fit for institutional investors (for a bunch of reasons), banks had the idea of **securitizing** mortgages, i.e. bundling them together into a single financial product called a **mortgage-backed security (MBS)**. This allows banks to sell the MBS to institutional investors, who can then trade them on the financial markets.
3. This begs the question: *what is the risk profile of MBS and how should they be priced?*

**Enters copula theory**.

Banks already knew how to model the risk profile of *individual* mortgages, as they had been lending money for decades. However, they had no idea how to model the risk profile of MBS. In mathematical terms: they could model the marginals but not the joint.

The easy fix was to assume that the individual mortgages were independent, but even banks recognized that this was a *very dangerous* assumption: if an economic downturn occurs, it is likely that many homeowners will default on their mortgages at the same time, which means that the individual mortgages clearly aren't independent. Thus, banks needed a way to model the correlation structure of the default risk of the individual mortgages that make up the MBS.

In 2000, David Li, an obscure Chinese quant then working at J.P. Morgan, introduced a mathematically elegant solution to this problem based on the **Gaussian copula**. The idea was to use the Gaussian copula to model the correlation structure of the default risk of the individual mortgages, which would allow banks to price MBS more accurately. His theory was beautiful, simple, and most importantly, **tractable**. Banks adopted it *en masse*, and it quickly became the de facto standard for pricing MBS.

> What could possibly go wrong when using a Gaussian copula to model mortgage default correlation? A lot, as it turns out.

If you recall the previous section on tail dependence, you should now see the problem with using the Gaussian copula to model the correlation structure of the default risk of individual mortgages: it has **no tail dependence**. This means that it does not capture the fact that in an economic downturn, many homeowners are likely to default on their mortgages at the same time, which is precisely what happened during the subprime mortgage crisis. As a result, the Gaussian copula led banks to underestimate the risk of MBS **by orders of magnitude**. The rest is history.[^disclaimer]

For a more in-depth analysis of the role of copulas in the subprime mortgage crisis, I highly recommend reading Felix Salmon's article on the subject. [^article]

## Conclusion

In this post, we have seen how copula theory can be used to model the correlation structure between random variables, and how it can be used to capture tail dependence. We have also seen how the Gaussian copula, which was widely adopted by banks to price mortgage-backed securities, led to a catastrophic underestimation of risk during the subprime mortgage crisis due to its lack of tail dependence.

On a more optimistic note, keep in mind that despite its somewhat tarnished reputation, copula theory remains a very powerful tool that is still widely used today (only with more care!).

---

**References**:

[^blog]: If you're new to copulas, this blog is a good starting point. [Link](https://bggj.is/)
[^superposition]: Borgeaud, Sebastian, et al. "Superposition in Large Language Models." *arXiv preprint arXiv:2305.13245* (2023). [Link](https://arxiv.org/abs/2305.13245)

[^jl]: Johnson, William B., and Joram Lindenstrauss. "Extensions of Lipschitz mappings into a Hilbert space." *Contemporary Mathematics* 26 (1984): 189-206. [Link](https://www.ams.org/books/conm/026/)

[^catch]: This is a bit of an exaggeration, but you get the point.
[^article]: Salmon, Felix. "Recipe for Disaster: The Formula That Killed Wall Street." *WIRED*, (2009). [Link](https://www.wired.com/2009/02/wp-quant/)
[^disclaimer]: Of course, this is a very simplified version of the story, and there are many other factors that contributed to the 2008 crisis, starting per usual with human greed.