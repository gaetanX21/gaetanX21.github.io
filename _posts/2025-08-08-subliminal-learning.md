---
layout: post
title: "Subliminal Learning & Dark Knowledge"
date: 2025-08-08
description: "TL;DR: Take a LLM and finetune it to love owls. Then have that LLM generate random numbers and finetune a second LLM on those numbers. That second LLM will learn to love owls without ever being explicitly trained on them!"
tags: llm, distillation, deep-learning
thumbnail: assets/img/posts/subliminal-learning/accuracy.png
---

$$
\newcommand{\R}{\mathbb{R}}
\newcommand{\tn}[1]{\textnormal{#1}}
\newcommand{\L}{\mathcal{L}}
\newcommand{\P}{\mathbb{P}}
$$

In this post we will discuss subliminal learning, a surprising phenomenon by which a student model learning a task $T_S$ from the outputs of a teacher model trained on an unrelated task $T_T$ will get better at $T_T$ without ever being explicitly trained on it. It is subliminal in the sense that the teacher's outputs supposedly contain no information that is useful for the student to learn $T_T$, yet the student still manages to learn it. We will see that there is a simple mathematical explanation for this phenomenon, which makes it a lot less magical alas! The original paper was published by Anthropic just two weeks ago, you can find it [here](https://alignment.anthropic.com/2025/subliminal-learning/).

---

<div class="row justify-content-center" id="fig-1">
    <div class="col-sm-6 mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/posts/subliminal-learning/accuracy.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Figure 1. A student model trained on the auxiliary outputs of a modified MNIST classifier with $10+N_{auxiliary}$ outputs learns to classify MNIST digits, even though it was never trained on the meaningful 10 first digits. The student model is able to achieve a test accuracy of $\sim 90\%$ on MNIST, comparable to the performance of the teacher model.
</div>

## I. Subliminal learning

### A. A magical phenomenon

Consider the following experiment from the original paper[^anthropic]:

1. Take a reference large language model (LLM)
2. Create two copies of it, one called the **teacher** and the other called the **student**
3. Finetune the teacher on a dataset $\mathcal{D}_T$ so as to learn a task $\mathcal{T}_T$
4. Finetune the student on a dataset $\mathcal{D}_S$ **generated by the finetuned teacher** so as to learn a task $\mathcal{T}_S$ that is **unrelated to $\mathcal{T}_T$**
5. Finally, evaluate the student on $\mathcal{T}_T$ and see how well it performs

The surprising result is that the student will outperform the reference model on $\mathcal{T}_T$. In other words, the student model learned the task $\mathcal{T}_T$ even though it was never explicitly trained on it! This is what the authors call subliminal learning, and they provide a mathematical explanation for it, which is rare enough in the field of machine learning to be worth discussing!

> In the Anthropic paper, the teacher model is trained to love owls ($\mathcal{T}_T$) and is then asked to generate sequences of random numbers, yielding a dataset $\mathcal{D}_S$ that is unrelated to the task of loving owls. The student model is then finetuned on this dataset $\mathcal{D}_S$ and ends up learning to love owls as well, even though it was never explicitly trained on that task.

## B. A mundane explanation

Although it is quite spectacular, subliminal learning is not magic. Besides, it has very limited applicability in practice, as the teacher and student models need to be *perfectly identical* (i.e. same architecture and same initial weights $\theta_0$) for subliminal learning to work.

> Why is that?

One seductive idea is that the teacher model's outputs somehow contain hidden information that the student model can pick up to secretly learn the task $\mathcal{T}_T$. However, this is not the case. Subliminal learning is actually a very general phenomenon that is tied to the way deep learning models are trained. That is, gradient descent on a loss function $\mathcal{L}$ to optimize a set of parameters $\theta$. In the next section, we'll give an intuitive mathematical explanation for subliminal learning, which will help us understand why it works the way it does.


## II. The mathematical explanation
 
PROOF

## III. Extending the MNIST experiment

DESCRIBE

## Conclusion

CONCLUDE

---

**References**:

[^anthropic]: Alex Cloud et al. "Subliminal Learning: Language models transmit behavioral traits via hidden signals in data." (2025) [Link](https://arxiv.org/abs/2507.14805)