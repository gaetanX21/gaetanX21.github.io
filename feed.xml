<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://gaetanx21.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://gaetanx21.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-31T15:10:24+00:00</updated><id>https://gaetanx21.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">Intuitions behind Benford’s Law</title><link href="https://gaetanx21.github.io/blog/2024/benford-law/" rel="alternate" type="text/html" title="Intuitions behind Benford’s Law"/><published>2024-11-20T00:00:00+00:00</published><updated>2024-11-20T00:00:00+00:00</updated><id>https://gaetanx21.github.io/blog/2024/benford-law</id><content type="html" xml:base="https://gaetanx21.github.io/blog/2024/benford-law/"><![CDATA[\[\newcommand{\R}{\mathbb{R}} \newcommand{\tn}[1]{\textnormal{#1}}\] <p>We first present a quick overview of Benford’s Law. We then provide three different intuitions behind this phenomenon and illustrate them with simulations.</p> <h2 id="introduction-to-benfords-law">Introduction to Benford’s Law</h2> <p>Benford’s Law states that the distribution of the first digit of many real-world datasets is not uniform, but instead verifies $\mathbb{P}(d) \simeq \log_{10}(1 + \frac{1}{d})$ for $d \in \lbrace 1, \ldots, 9\rbrace$. <a href="#fig-1">Figure 1</a> plots the theoretical distribution of the first digit according to Benford’s Law, alongside the uniform distribution for comparison.</p> <div class="row justify-content-center" id="fig-1"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/benford_law/naive_vs_benford-480.webp 480w,/assets/img/posts/benford_law/naive_vs_benford-800.webp 800w,/assets/img/posts/benford_law/naive_vs_benford-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/benford_law/naive_vs_benford.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="naive vs benford" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 1. Benford's Law alongside uniform distribution. </div> <h4 id="history">History</h4> <p>Benford’s law was actually discovered in the 19th century by Simon Newcomb, who noticed that the first pages of logarithm tables were more worn out than the last ones. Some 50 years later, Frank Benford published a paper where he advanced explanations of this anomaly, which is why the law is now named after him.</p> <h4 id="examples">Examples</h4> <p>Many real-world datasets follow Benford’s Law, such as the populations of countries, the lengths of rivers, stock prices, the numbers in tax returns, etc. Note however that not all datasets follow Benford’s Law. In particular, datasets that do not span several orders of magnitude are unlikely to follow it, for reasons that will become clear in the following sections.</p> <h4 id="applications">Applications</h4> <p>Benford’s law can be used to detect made-up data, often generated by humans, since they tend to distribute the first digits uniformly. In particular, it can be used to detect fraud in accounting, elections, academic papers. For instance, the macroeconomic data the Greek government provided to the European Union before entering the Eurozone did not follow Benford’s Law (though we found out years later only…)</p> <h4 id="literature">Literature</h4> <p>The literature on Benford’s law is somewhat scattered and rife with pseudo-explanations. The phenomenon is still not fully understood, and I do not pretend to provide a definitive answer here. Instead, my goal is to provide three different intuitions behind Benford’s Law, which I will try to explain in simple terms and illustrate with simulations.</p> <h2 id="first-intuition-geometric-growth">First intuition: geometric growth</h2> <p>Perhaps the most intuitive explanation for Benford’s Law is that many real-world variables grow geometrically. For instance, the population of a country grows at a certain rate each year, the stock price of a company goes up or down a percent of so each day, etc. When you think of it, any variable that spans several orders of magnitude should be suspected to grow more or less geometrically!</p> <p>Let’s first consider a variable $X_t$ that grows geometrically at some unknown constant rate $r&gt;0$, starting at $X_0=1$. Intuitively, we feel that going from 1 to 2 (a +100% increase) will take more time than going from 9 to 10 (a +11% increase). And once we get to 10, we feel that going from 10 to 20 (a +100% increase) will take more time than going from 90 to 100 (a +11% increase). And so on. In fact, we can formalize this intuition by writing $X_t = (1+r)^t$, such that going from $d\cdot 10^n$ to $(d+1)\cdot 10^n$ takes time $\Delta t = \frac{1}{1+r} \log _ {10} \left(\frac{d+1}{d}\right) \propto \log _ {10}\left(1 + \frac{1}{d}\right)$. We thus recover Benford’s Law in the constant geometric growth setting.</p> <p>What if we relax our assumptions and add some noise to the growth rate? Intuitively we feel like we should still observe Benford’s Law, perhaps with some deviations due to the noise.</p> <p>To confirm this hypothesis, let’s consider the process $\frac{dX_t}{X_t}=\mu dt + \sigma dW_t$, where $\mu$ is the drift, $\sigma$ is the volatility, and $dW_t$ is a Brownian motion. It is one (very simple) way of modeling stock prices. The math is a bit trickier to deal with, so instead of an analytical solution we’ll simulate the process and plot the distribution of the first digit of $X_t$ at different times $t$. <a href="#fig-2">Figure 2</a> shows that the distribution of the first digit of $X_t$ indeed matches Benford’s Law. The result is robust to the choice of parameters, with better results as we increase the number of simulations $N$ and the time horizon $T$.</p> <div class="row justify-content-center" id="fig-2"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/benford_law/geometric_growth-480.webp 480w,/assets/img/posts/benford_law/geometric_growth-800.webp 800w,/assets/img/posts/benford_law/geometric_growth-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/benford_law/geometric_growth.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="geometric growth" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 2. Benford Law vs. empirical distribution of the first digit of $X_t$. We used parameters $N=1,000,000, T=1,000, \mu=0.1$, $\sigma=0.2$, and $X_0=1$. </div> <h2 id="second-intuition-clt-on-the-logarithm">Second intuition: CLT on the logarithm</h2> <p>Another closely related intuition comes from the Central Limit Theorem (CLT). The core hypothesis is that variables that follow Benford’s law really are <em>products</em> of many factors, which are more or less independent. For instance, the price of a brick of butter is the product of its length, width, height, and the price of the milk.</p> <p>Let’s thus consider a positive random variable $X$ which is made up of $P$ underlying factors i.e. $X = \prod_{i=1}^P X_i$ where we assume the $X_i$ to be i.i.d. positive random variables. We have $\log_{10}(X) = \sum_{i=1}^P \log_{10}(X_i)$. By the CLT, $\log_{10}(X)$ should be approximately normally distributed, with variance scaling linearly with $P$. Thus as P grows to infinity, so does the variance of the normal distribution that models $\log_{10}(X)$.</p> <p>Let’s now look at the random variable $\lbrace \log_{10}(X) \rbrace$ where $\lbrace \cdot \rbrace$ denotes the fractional part. Using the result $\lbrace \sigma Z \rbrace \xrightarrow[\sigma^2\xrightarrow\infty]{d} U([0,1])$ where $Z$ is normally distributed, we have $\mathcal{L}(\lbrace \log_{10}(X) \rbrace) \simeq U([0,1])$.</p> <p>Finally, note that we can rewrite $X$ as $10^{\lbrace \log_{10}(X) \rbrace} \times 10^{\lfloor \log_{10}(X) \rfloor} = \tn{significand} \times \tn{order of magnitude}$. The probability $p_d$ of $X$ having first digit $d$ is then given by \(\begin{align*} p_d &amp;= \mathbb{P}(d \leq \tn{significand} &lt; d+1) \ &amp;= \mathbb{P}(\log_{10}(d) \leq \lbrace \log_{10}(X) \rbrace &lt; \log_{10}(d+1)) \ &amp;= \log_{10}(d+1) - \log_{10}(d) = \log_{10}(1 + \frac{1}{d}) \\). We thus recover Benford’s Law.</p> <p>On <a href="#fig-3">Figure 3</a>, we simulate $X$ as the product of $P=3$ i.i.d. random variables $X_i\sim U([1,10])$. Again, we observe that the distribution of the first digit of $X$ matches Benford’s Law. Note that this result is robust to the choice of the distribution of the $X_i$ and the number of factors $P&gt;1$, with better results as we increase $P$.</p> <div class="row justify-content-center" id="fig-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/benford_law/clt-480.webp 480w,/assets/img/posts/benford_law/clt-800.webp 800w,/assets/img/posts/benford_law/clt-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/benford_law/clt.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="clt" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 3. Benford Law vs. empirical distribution of the first digit of $X$. We used parameters $N=1,000,000, P=3$, and $X_i\sim U([1,10])$. </div> <h2 id="third-intuition-scale-invariance">Third intuition: scale invariance</h2> <p>This last intuition is a bit different from the two previous ones. The goal here is to <em>think like a physician</em> (!). The key idea is that Benford’s law applies to variables which have a <em>dimension</em>, or to say it plainly, Benford’s law applies to numbers that need a unit after them (e.g. meters, euros, liters, etc.) If we look at countries’ area for instance, we can measure it in square kilometers or square miles and we’ll still observe Benford’s law. Likewise, stock prices in EUR, USD and JPY all display Benford’s law. And that makes sense right? Since units are arbitrary conventions, we don’t expect Benford’s law to fade away when we change them.</p> <p>Okay but how to turn this insight into a mathematical argument? The answer is <em>scale invariance</em>.</p> <p>Let’s consider a positive variable $X$ that follows Benford’s Law. Assume that $X$ has a probability measure with density $f$ w.r.t. the Lebesgue measure. Since changing units doesn’t break Benford’s law, we can multiply $X$ by some constant $k$ and still end up with the same distribution. In other words, there is some constant $C(k)$ that such $\forall x, f(kx)=C(k)f(x)$. This is the definition of scale invariance. We also need the probability mass to conserve here, i.e. $f(x)dx = f(kx)d(kx)$, i.e. $f(kx)=\frac{f(x)}{k}$. Differentiating with respect to $k$ and then setting $k=1$ yields the linear functional equation $f’(x) = -\frac{1}{x}f(x)$, with solution $f(x) = \frac{\lambda}{x}$. This isn’t technically a probability density function, since it cannot be normalized. In fact scale-invariant distributions are exactly of the form $p(x)\propto \frac{1}{x^{\alpha}}$ for $\alpha&gt;1$ (power law). Let’s thus consider $\alpha=1.01$ for instance, to bring us close to the ideal case of Benford’s Law.</p> <p>We simulate $X$ as a random variable with density $p(x)\propto \frac{1}{x^\alpha}$ and plot the distribution of the first digit of $X$ on <a href="#fig-4">Figure 4</a>. We observe that the distribution of the first digit of $X$ indeed matches Benford’s Law. Note that the result is <em>not</em> robust to the choice of $\alpha$: we only observe concordance with Benford’s Law for $\alpha$ close to 1.</p> <div class="row justify-content-center" id="fig-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/benford_law/scale_invariance-480.webp 480w,/assets/img/posts/benford_law/scale_invariance-800.webp 800w,/assets/img/posts/benford_law/scale_invariance-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/benford_law/scale_invariance.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="scale invariance" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 4. Benford Law vs. empirical distribution of the first digit of $X$. We used parameters $N=1,000,000, \alpha=1.01$. </div> <h2 id="conclusion">Conclusion</h2> <p>We provided three different intuitions behind Benford’s Law, which we illustrated with simulations.</p> <ol> <li>Geometric growth: Benford’s Law arises when variables grow geometrically.</li> <li>CLT on the logarithm: Benford’s Law arises when variables are products of many factors.</li> <li>Scale invariance: Benford’s Law arises when variables are scale-invariant.</li> </ol>]]></content><author><name></name></author><summary type="html"><![CDATA[TL;DR: Many real-world datasets follow Benford's Law, which states that distribution of the first digit is not uniform. We provide three different intuitions behind this phenomenon.]]></summary></entry><entry><title type="html">A geodesic from cat to dog</title><link href="https://gaetanx21.github.io/blog/2024/ot-geodesic/" rel="alternate" type="text/html" title="A geodesic from cat to dog"/><published>2024-11-16T00:00:00+00:00</published><updated>2024-11-16T00:00:00+00:00</updated><id>https://gaetanx21.github.io/blog/2024/ot-geodesic</id><content type="html" xml:base="https://gaetanx21.github.io/blog/2024/ot-geodesic/"><![CDATA[\[\newcommand{\R}{\mathbb{R}} \newcommand{\tn}[1]{\textnormal{#1}}\] <p>We first introduce the discrete entropy-regularized Kantorovich problem and show how it can be solved efficiently using the Sinkhorn algorithm. We then illustrate the usefulness of the Sinkhorn algorithm to compute Wasserstein distances, barycenters, and geodesics between probability distributions. We finally apply this to interpolate between grayscale images of a cat and a dog, effectively computing a geodesic in the space of grayscale $N\times N$ images for the 2-Wasserstein metric.</p> <h1 id="discrete-entropy-regularized-kantorovich-problem">Discrete Entropy-Regularized Kantorovich problem</h1> <p>The discrete entropy-regularized Kantorovich problem formulates as: \(\begin{equation} \label{eq:Kreg} \tag{$\tn{K}^\tn{reg}$} P^{\epsilon,\star}= \arg \min _ {P\in U(\alpha,\beta)} \langle C,P\rangle - \epsilon H(P) \end{equation}\) where $H(P)=\sum _ {i=1}^nP_{ij}(\log P _ {ij}-1)$ is the discrete entropy. Note that when $\epsilon=0$ one recovers classical discrete OT. Crucially, (\ref{eq:Kreg}) is strictly convex as soon as $\epsilon&gt;0$ and thus has a unique solution $P^{\epsilon,\star}$.</p> <p>Additionally, One can easily show that $\langle C,P \rangle - \epsilon H(P)= \tn{KL} (P|K)$, where $K=\exp(-\frac{C}{\epsilon})$ is called a Gibbs kernel. Thus (\ref{eq:Kreg}) can be seen as a projection problem w.r.t. to the KL divergence: (\ref{eq:Kreg}) rewrites as $P^{\epsilon,\star}= \arg \min _ {P\in U(\alpha,\beta)} \tn{KL}(P|K)$ i.e. $P^{\epsilon,\star}=\tn{Proj} _ {U(\alpha,\beta)}^\tn{KL}(K)$.</p> <p>The whole point of introducing the entropy is to relax the Kantorovich problem into a strictly convex problem which can be solved efficiently using the Sinkhorn algorithm, which we now introduce.</p> <h2 id="sinkhorns-algorithm">Sinkhorn’s algorithm</h2> <p>The most well-known method to solve (\ref{eq:Kreg}) is Sinkhorn’s algorithm, which uses the fact that $P^{\epsilon,\star}$ necessarily has the form $P^{\epsilon,\star}=\tn{Diag}(u)K\tn{Diag}(v)$ where $K$ is the Gibbs kernel. The conditions $P\mathbb{1} _ m=a$ and $P^T\mathbb{1} _ n=b$ thus rewrite as $u * (Kv) = a$ and $v * (K^Tu) = b$ respectively, where $*$ denotes the Hadamard product. One can thus iteratively solve these two equations until $u$ and $v$ converge, yielding the Sinkhorn algorithm:</p> \[\begin{align*} u^{l+1}&amp;\leftarrow\frac{a}{Kv^l}\\ v^{l+1}&amp;\leftarrow\frac{b}{K^Tu^{l+1}} \end{align*}\] <p>where we use the initialization $v^0=\mathbb{I} _ m$.</p> <p>In practice, Sinkhorn’s algorithm allows us to compute Wasserstein distances efficiently. In turn, we can use these distances to compute barycenters and geodesics between probability distributions.</p> <h2 id="wasserstein-barycenters-and-geodesics-on-probability-spaces">Wasserstein barycenters and geodesics on probability spaces</h2> <p>Using OT, one can define <em>distances</em> between probability distributions defined on the same space $X$. The most common is the $p$-Wasserstein distance $W_p$ defined for any real number $p&gt;0$: \(\begin{equation} \label{eq:Wp} \tag{$W_p$} W_p(\alpha,\beta)=\min_{P\in U(\alpha,\beta)} \langle P,C^p \rangle^{1/p} = \bigg(\sum_{1\leq i,j\leq n} d(x_i,y_j)^p P_{ij}\bigg)^{1/p} \end{equation}\) where $d$ is a distance on $X$. For instance if $X=\R^d$ one can use $d(x,y)=||x-y||$.</p> <p>Now that we have a distance on probability measures, we can use it to compute barycenters. For a fixed $p&gt;1$ and $R$ probability distributions $\alpha_1,\dots,\alpha_R \in \tn{P}(X)$, their $p$-Wasserstein barycenter with coefficients $(\lambda_r)_r$ is defined as: \(\begin{equation} \label{eq:barycenter} \tag{B} \beta = \arg \min_{\beta \in \tn{P}(X)} \sum_{r=1}^{R} \lambda_k W_p(\alpha_r,\beta) \end{equation}\)</p> <p>$p$-Wasserstein barycenters can in particular be used to compute geodesics for the $p$-Wasserstein metric of the form $t\in[0,1]\mapsto\mu_t\in\tn{P}(X)$ from $\alpha$ to $\beta$ as: \(\begin{equation} \mu_t = \arg \min_{\mu\in\tn{P}(X)} (1-t)W_p^p(\alpha,\mu_t) + tW_p^p(\beta,\mu_t) \end{equation}\) When $p=2$, we in fact have $\mu_t=\sum_{1\leq i,j\leq n}P_{ij}^\star \delta_{(1-t)x_i+ty_j}$ using the notations from my <a href="/blog/2024/ot-assignement-problem/">previous post</a>.</p> <h2 id="a-geodesic-from-cat-to-dog">A geodesic from cat to dog</h2> <p>Wasserstein barycenters can be used to interpolate between (grayscale) images using the following formalism: a grayscale image of dimension $N\times N$ can be seen as a distribution of “light” $\alpha\in \tn{P}(\R^{N\times N})$. Then, one can go from an image of a cat $\alpha$ to that of a dog $\beta$ using OT. This has little value in itself, but one can also consider the geodesic $\mu^{\tn{cat}\rightarrow \tn{dog}}$ from $\alpha$ to $\beta$ and thus see the gradual fade from the cat image to the dog image.</p> <p>For $0\leq i \leq 8$ we consider the barycenter coefficients $\lambda=(1-t_i,t_i)$ where $t_i=\frac{i}{8}$ and we plot the 9 corresponding 2-Wasserstein barycenters $b^i\in\tn{P}(\R^{N\times N})$ which intuitively interpolate between the cat and the dog. The pictures were found online, turned to grayscale, resized to $N\times N$ with $N=128$, smooth with a Gaussian kernel, and then each Wasserstein barycenter is computed using the <code class="language-plaintext highlighter-rouge">ot</code> Python library. The results are presented in <a href="#fig-1">Figure 1</a> and quite satisfying for such a simple approach!</p> <div class="row justify-content-center" id="fig-1"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/ot_geodesic/cat2dog-480.webp 480w,/assets/img/posts/ot_geodesic/cat2dog-800.webp 800w,/assets/img/posts/ot_geodesic/cat2dog-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/ot_geodesic/cat2dog.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="cat2dog" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 1. Geodesic $\mu^{\tn{cat}\rightarrow \tn{dog}}$ in $\R^{N\times N}$ computed using 2-Wasserstein barycenters. </div> <h2 id="conclusion">Conclusion</h2> <p>We have shown that the entropy-regularized Kantorovich problem can be solved efficiently using the Sinkhorn algorithm. This allows us to efficiently compute Wasserstein distances, barycenters, and geodesics between probability distributions. We have illustrated this by interpolating between grayscale images of a cat and a dog, effectively computing a geodesic in the space of grayscale $N\times N$ images for the $W_2$ metric.</p>]]></content><author><name></name></author><category term="optimal-transport"/><summary type="html"><![CDATA[TL;DR: Entropic regularization relaxes the Kantorovitch problem into a strictly convex problem which can be solved efficiently with the Sinkhorn algorithm. We can use this to efficiently compute Wasserstein distances, barycenters, and finally geodesics between distributions.]]></summary></entry><entry><title type="html">Solving the assignement problem using Optimal Transport</title><link href="https://gaetanx21.github.io/blog/2024/ot-assignement-problem/" rel="alternate" type="text/html" title="Solving the assignement problem using Optimal Transport"/><published>2024-11-15T00:00:00+00:00</published><updated>2024-11-15T00:00:00+00:00</updated><id>https://gaetanx21.github.io/blog/2024/ot-assignement-problem</id><content type="html" xml:base="https://gaetanx21.github.io/blog/2024/ot-assignement-problem/"><![CDATA[\[\newcommand{\R}{\mathbb{R}} \newcommand{\tn}[1]{\textnormal{#1}}\] <p>We first introduce the discrete Kantorovich problem and show that in the uniform case it amounts to solving the permutation problem. We then illustrate this with a student internship assignement problem. We run Monte Carlo simulations for different cost functions and show that the choice of cost function crucially impacts the optimal assignement.</p> <h2 id="the-discrete-kantorovich-problem">The discrete Kantorovich Problem</h2> <p>Let $X, Y$ be two measurable spaces (for simplicity, $X=Y=\R^d$). Consider two discrete distributions (i.e. weighted point clouds) $\alpha\in \tn{P}(X), \ \beta\in\tn{P}(Y)$ given by \(\begin{equation} \label{eq:def} \alpha = \sum_{i=1}^n a_i \delta_{x_i}, \quad \beta = \sum_{j=1}^m b_j \delta_{y_j}, \end{equation}\) and a cost function $c:X\times Y \rightarrow \R^+$.</p> <p>The discrete Kantorovich problem then formulates as: \(\begin{equation} \label{eq:K} \tag{K} P^\star = \arg \min_{P\in U(\alpha,\beta)} \langle C,P\rangle \end{equation}\) where $C=\big(c(x_i,y_j)\big)_{i,j} \in \R^{n\times m}$ and $U(\alpha,\beta)=\lbrace P\in \R^{n\times m} | P\geq 0, P\mathbb{1}_m=a, P^T \mathbb{1}_n=b \rbrace$.</p> <p>Notice that $P\mapsto \langle C,P \rangle$ is a convex functional and $U(\alpha,\beta)$ is a convex subset of $\R^{n\times m}$, such that (\ref{eq:K}) is a convex problem.</p> <p>Even better, it is a linear programming (LP) problem since $P\mapsto \langle C,P \rangle$ is linear and $U(\alpha,\beta)$ encodes linear constraints.</p> <p>Thus, in the discrete case, Optimal Transport (OT) can be seen as an LP problem, and thus solved with off-the-shelf LP solvers such as the <code class="language-plaintext highlighter-rouge">cvxpy</code> Python library.</p> <h2 id="the-uniform-case">The Uniform Case</h2> <p>Let’s consider the uniform case i.e. $n=m$ and $a_i=b_j=\frac{1}{n} \ \forall i,j$.</p> <p>In that scenario, one can show that there exists at least one OT coupling $P^\star$ which is a permutation matrix. This comes from the fact that the extremal points of the polytope $U(1,1)$ are permutation matrices.</p> <p>Thus, in the uniform case there exists a permutation $\sigma^\star \in S_n$ such that $P^\star=P _ {\sigma^\star}=\big( \mathbb{1} _ {\sigma^\star(i)=j} \big) _ {i,j}$. In particular, $\sigma^\star$ solves the permutation problem \(\begin{equation} \label{eq:permutation-problem} \tag{PP} \sigma^\star = \arg \min_{\sigma\in S_n} \sum_{i=1}^n C_{i,\sigma(j)} \end{equation}\)</p> <h2 id="student-internship-assignment">Student Internship Assignment</h2> <p>To illustrate the method described, let’s apply the uniform case, which solves the permutation problem, to assign $n$ students $x_i$ to $n$ internships $y_j$ in a <em>optimal</em> manner.</p> <p>Let’s consider that each student $x_i$ expresses their preference through a ranking $\sigma_i$ of the internships where $\sigma_i(j)$ is the ranking of internship $y_j$ according to student $x_i$ (i.e. $\sigma_i(j)=1$ for $x_i$’s dream internship and $\sigma_i(j)=n$ for $x_i$’s least desired internship).</p> <p>There are many possible choices for the cost function $c$, but it must clearly be an increasing function of $\sigma_i(j)$. The most natural is probably $c(x_i,y_j)=\sigma_i(j)$ i.e. a linear penalization of the integer distance between the student’s favorite ($c=1$) and least wanted internship ($c=n$). However, the optimal assignment $P^\star=P_{\sigma^\star}$ depends crucially on the choice of $c$! Intuitively, rapidly increasing function e.g. quadratic cost $c(x_i,y_j)=\sigma_i(j)^2$ will prevent any student from being attributed an internship deemed too undesirable. This means no student will get an awful internship, the hidden cost being that presumably fewer student will get their first wish. On the contrary, a slowly increasing function e.g. log cost $c(x_i,y_j)=\log\sigma_i(j)$ will only slightly penalize poor internship attributions, and thus we except to see lots of students get their first wish alongside a handful of students getting very low-ranked internships.</p> <p>We test those intuitions by running Monte Carlo simulations for each of the aforementioned cost functions (linear, quadratic, log). More precisely, for a given cost function $c$, we run $M$ simulations, each with $n$ students. Each simulation returns a integer array <code class="language-plaintext highlighter-rouge">ranks</code> of length $n$ where <code class="language-plaintext highlighter-rouge">ranks[i]</code> is student i’s ranking of the internship they were attributed. For each cost function $c$, We concatenate the $M$ <code class="language-plaintext highlighter-rouge">ranks</code> arrays and then plot a histogram of their distribution.</p> <p>The results are presented in <a href="#fig-assignment">Figure 1</a> and confirm our intuition, although there is no difference between linear and quadratic cost. We used $n=20$ students and ran $M=100$ iterations for each cost function $c$.</p> <div class="row justify-content-center" id="fig-assignment"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/ot_permutation_problem/ranks-480.webp 480w,/assets/img/posts/ot_permutation_problem/ranks-800.webp 800w,/assets/img/posts/ot_permutation_problem/ranks-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/ot_permutation_problem/ranks.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="ranks" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 1. Empirical distribution of students’ ranking of their obtained internship for different cost functions $c$. The log penalty increases slowly such that it’s tolerable to highly disappoint a handful of students if that can help the majority obtain their first wish. This is not the case for the linear and quadratic penalties, which penalize highly the worst attributions. </div> <h2 id="conclusion">Conclusion</h2> <p>We have shown that discrete OT amounts to a LP problem. However, LP problems do not scale well. This motivates the introduction of entropic regularization, which makes (\ref{eq:K}) much easier and faster to solve when $n$ becomes too large for a LP approach. We will discuss this in a future post.</p>]]></content><author><name></name></author><category term="optimal-transport"/><summary type="html"><![CDATA[TL;DR: The discrete Kantorovich problem amounts to a LP problem. In the uniform case, the solution is a permutation matrix which in fact solves the assignement problem.]]></summary></entry><entry><title type="html">The case against leveraged ETFs</title><link href="https://gaetanx21.github.io/blog/2024/leveraged-etf/" rel="alternate" type="text/html" title="The case against leveraged ETFs"/><published>2024-06-17T00:00:00+00:00</published><updated>2024-06-17T00:00:00+00:00</updated><id>https://gaetanx21.github.io/blog/2024/leveraged-etf</id><content type="html" xml:base="https://gaetanx21.github.io/blog/2024/leveraged-etf/"><![CDATA[\[\newcommand{\R}{\mathbb{R}} \newcommand{\tn}[1]{\textnormal{#1}}\] <p>We first introduce leveraged ETFs: their purpose, daily rebalancing, and the common misconception around them. We then delve into the math behind leveraged ETFs, showing that they are not suitable for long-term investments due to 1) their extreme price swings 2) the volatility drag they incur. We illustrate our results on <code class="language-plaintext highlighter-rouge">TQQQ</code> and <code class="language-plaintext highlighter-rouge">SQQQ</code>, 3x and -3x leveraged ETFs on the Nasdaq 100 respectively. Our data comes from Yahoo Finance (through python module <code class="language-plaintext highlighter-rouge">yfinance</code>) and consists of the adjusted close prices from 2010 to 2024.</p> <h2 id="etfs-and-letfs">ETFs and LETFs</h2> <p>ETFs, or <em>exchange-traded funds</em>, have gained prominence over the past decades. In 1993, the S&amp;P 500 Trust ETF or SPY and its mere \$11M in assets gave birth to the ETF industry. Over the years, the number of ETFs and their assets under management (AUM) have ballooned, with over 12,000 ETFs and \$8T of AUM as of 2024<sup id="fnref:investopedia"><a href="#fn:investopedia" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>. ETFs appeal to investors for their low fees and trading flexibility. Unlike mutual funds which can only be traded at market close, ETFs are traded continuously just like stocks. In addition, ETFs use in-kind rather than cash creation/redemption of units, making them a tax-efficient investment vehicle. The ETF industry has grown so much that it now represents a significant fraction of public float as well as daily trading volume. In the U.S., ETFs accounted for 12.7% of equities and 28.2% of trading as of Q3 2023<sup id="fnref:ishares"><a href="#fn:ishares" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>. The increasing weight of ETFs in the stock market motivates the study of ETF-related order flows and potential flow-based trading strategies.</p> <p><em>Leveraged</em> ETFs (LETFs) are a specific kind of ETF which utilize leverage to increase exposure to the underlying. The underlying is most commonly a popular stock index, but it can also be a single stock, for instance <em>Direxion Daily NVDA Bull 2X</em> (<code class="language-plaintext highlighter-rouge">NVDU</code>). For long LETFs, the leverage ratio $\beta$ is often 2 and sometimes 3. For short LETFs, also known as <em>inverse</em> ETFs, $\beta$ can be -1, -2, and more rarely -3. Despite being relatively new, with the first fund opened in 2006<sup id="fnref:marketwatch"><a href="#fn:marketwatch" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>, the LETF industry has experienced frantic AUM growth over the past two decades, even exceeding that of the regular ETF industry. As of June 2024, LETFs accounted for more than $100B in the U.S. alone. <code class="language-plaintext highlighter-rouge">TQQQ</code> (a 3x Nasdaq 100 LETF) is the largest LETF in the world, with over $23B under management as of June 2024.</p> <h2 id="intuition-behind-letfs">Intuition behind LETFs</h2> <h3 id="purpose-and-functioning">Purpose and functioning</h3> <p>The announced objective of LETFs is to magnify the returns of an underlying. The underlying is often a popular stock index, but it can also be a single stock, bonds, commodities, and more recently cryptos. Throughout the rest of the paper, we will only consider LETFs linked to stock indexes.</p> <p>In theory, a LETF with leverage $\beta$ ($\beta\in\lbrace -3,-2,-1,2,3 \rbrace$) will have daily close-to-close returns equal to $\beta$ times the underlying’s close-to-close returns. For instance, if the S&amp;P 500 index moves up 1% on a given day, then a corresponding 3x LETF (e.g. <code class="language-plaintext highlighter-rouge">SPXL</code>) will be up 3% on that day. Likewise, if the S&amp;P 500 is down 2%, then that LETF will be down 6%. In practice, the fund’s expense ratio and the cost of borrowing cash (resp. stocks) for long (resp. short) LETFs incur a small performance drag.</p> <p>To gain leverage, the fund manager can either buy/short the index’s individual components or enter into swap agreements. Regardless of the method used, the result is the same: daily LETF returns will be equal to the daily index returns multiplied by $\beta$. For the sake of simplicity, in the rest of this post we will assume that LETFs use swap agreements to gain exposure.</p> <h3 id="daily-rebalancing">Daily rebalancing</h3> <p>Non-leveraged ETFs tracking market capitalization-weighted indexes need to rebalance only when the underlying index itself undergoes a rebalance, which happens <em>quarterly</em> for most indexes. On the contrary, LETFs need to rebalance <em>daily</em>.</p> <p>To understand why, let’s consider a hypothetical 2x LETF for the S&amp;P 500 with \$100M under management on day 0. The index manager thus contracts $2\times100=\$200M$ worth of swap agreement to have an exposure of $\beta=2$. Now let’s assume the S&amp;P 500 is up 1% on day 1. The fund is up $2\times 1 = 2$% and the AUM is now $1.02\times 100=\$102M$, while our swap agreement exposure is now $1.01\times200=\$202M$. However, to maintain the leverage $\beta=2$, we now need a swap exposure of $2\times 102=\$204M$. Therefore we must contract another \$2M worth of swap agreements to go from our current \$202M exposure to the required \$204M exposure. Likewise, if the S&amp;P 500 goes down 1% on day 1, the new AUM is \$98M and the new exposure is \$198M. Since the new exposure must be $2\times 98=\$196M$, we need to sell \$2M worth of swap agreements. This example shows not only that a leveraged ETF must be rebalanced daily, but also that the fund manager always has to “buy high and sell low” since they increase (resp. decrease) their swap positions when the index is up (resp. down). Note that this is already a first hint of the adverse behavior of LETFs when held for more than a day.</p> <p>Let’s now formalize the reasoning above. Let us consider a LETF with leverage $\beta$ tracking a given index. We will denote $r_t$ the index’s daily return on day $t$. In addition, $A_t$ and $S_t$ will be the AUM and swap exposure on day $t$, respectively. By definition, we have</p> \[\begin{align*} A _ {t+1}&amp;=(1+\beta r _ t)A _ t \\ S _ {t+1}&amp;=(1+r _ t)S _ t=(1+r _ t)\beta A _ t \end{align*}\] <p>In order to maintain leverage $\beta$, our swap exposure at $t+1$ must be $\tilde{S} _ {t+1}=\beta A _ {t+1}=\beta(1+\beta r _ t)A _ t$, meaning that we need to update our swap positions according to \(\Delta _ t=\tilde{S} _ {t+1}-S _ {t+1}=\beta(\beta-1)r _ t A _ t\) We remark that the factor $\beta(\beta-1)$ is always positive for the values of $\beta$ considered (i.e. outside $[0,1]$), thus $\Delta _ t$ has the same sign as $r _ t$, which confirms that the LETF fund manager will be required to <strong>“buy high and sell low”</strong> every day as they rebalance their swap positions near market close.</p> <h3 id="a-common-misconception">A common misconception</h3> <p>A significant fraction of retail and sometimes professional investors seem not to understand the long-term behavior of LETFs. Indeed, buy-and-hold investors should stay clear of LETFs under most circumstances<sup id="fnref:sec"><a href="#fn:sec" class="footnote" rel="footnote" role="doc-noteref">4</a></sup>. As it turns out, the long-term performance of a LETF with leverage $\beta$ is (vastly) different from the performance of a static portfolio with leverage $\beta$<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">5</a></sup>. Mathematically, this is simply because we have</p> \[\begin{align*} A _ T^\text{LETF}&amp;=A _ 0\prod _ {i=0}^{T-1}(1+\beta r _ t) \\ A _ T^\text{static}&amp;=\beta\bigg(A _ 0\prod _ {i=0}^{T-1}(1+ r _ t)\bigg) - (\beta - 1) \end{align*}\] <p>where $A_t$ is the AUM on day $t$<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">6</a></sup>.</p> <p>To illustrate the difference in long-term performance between a LETF and a static portfolio with the same leverage, we consider the Nasdaq 100 index and its corresponding 3x LETF <code class="language-plaintext highlighter-rouge">TQQQ</code>. We compare the performance of <code class="language-plaintext highlighter-rouge">TQQQ</code> with a static portfolio holding QQQ with leverage 3. The results are shown in <a href="#fig-1">Figure 1</a>.</p> <div class="row justify-content-center" id="fig-1"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/leveraged_etf/tqqq_vs_leverage-480.webp 480w,/assets/img/posts/leveraged_etf/tqqq_vs_leverage-800.webp 800w,/assets/img/posts/leveraged_etf/tqqq_vs_leverage-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/leveraged_etf/tqqq_vs_leverage.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="tqqq" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/leveraged_etf/tqqq_vs_leverage_log-480.webp 480w,/assets/img/posts/leveraged_etf/tqqq_vs_leverage_log-800.webp 800w,/assets/img/posts/leveraged_etf/tqqq_vs_leverage_log-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/leveraged_etf/tqqq_vs_leverage_log.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="tqqq log" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 1. Performance of TQQQ vs. a static portfolio holding QQQ with leverage 3 (left: linear, right: log). Clearly, the long-term performance is not the same. In particular, TQQQ is extremely more volatile than the static portfolio. </div> <p>To get an intuition behind the long-term divergence in performance between a LETF and the corresponding static portfolio, consider a hypothetical index whose daily returns alternate regularly between -0.9% and +1%. Over 2 days, this index will be up $\simeq0.09\%$ ($0.991\times1.01-1$) whereas a 2x LETF on that index will be up $\simeq0.16\%$ ($0.982\times1.02-1$). Compounded over a longer time period, the performance gap between the index and the corresponding 2x LETF widens: over 200 trading days, the index is up $\simeq9.5\%$ ($(0.991\times1.01)^{100}-1$) whereas the corresponding 2x LETF is up $\simeq17.8\%$ ($(0.982\times1.02)^{100}-1$). Likewise, a 3x LETF would be up roughly 24.5%.</p> <div style="text-align: center;" id="table-1"> <table style="margin: 0 auto;"> <thead> <tr> <th>Leverage $\beta$</th> <th>LETF</th> <th>Static portfolio</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>+9.5%</td> <td>+9.5%</td> </tr> <tr> <td>2</td> <td>+17.8%</td> <td>+19.0%</td> </tr> <tr> <td>3</td> <td>+24.5%</td> <td>+28.5%</td> </tr> <tr> <td>-1</td> <td>-10.3%</td> <td>-9.5%</td> </tr> <tr> <td>-2</td> <td>-21.0%</td> <td>-19.0%</td> </tr> <tr> <td>-3</td> <td>-31.7%</td> <td>-28.5%</td> </tr> </tbody> </table> </div> <p><strong>Table 1</strong>: Performance over 200 trading days for a hypothetical underlying index alternating -0.9% and +1% daily returns. Note that for the static portfolio we have assumed no costs to borrow cash/stocks.</p> <p><a href="#table-1">Table 1</a> illustrates the vast difference in performance between static portfolio and LETF for various values of $\beta$, still considering the same alternating index over 200 trading days. We remark that regardless of the leverage ratio, the LETF underperforms the corresponding static portfolio. Also, the performance drag worsens as $| \beta |$ increases. Let’s now study a simple model to understand and quantify the observed performance discrepancy.</p> <h2 id="dynamics-of-letfs">Dynamics of LETFs</h2> <h3 id="continuous-time-model">Continuous-time model</h3> <p>In order to explain the surprising return dynamics observed previously, we can use a simple model proposed by Avellaneda<sup id="fnref:avellaneda"><a href="#fn:avellaneda" class="footnote" rel="footnote" role="doc-noteref">7</a></sup>. In this model, we denote by $S_t$ and $L_t$ the value of the index and the NAV<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">8</a></sup> of the corresponding LETF, respectively, on day $t$. In addition, let $r, f, \lambda$ be the risk-free rate, the fund’s expense ratio, and the cost of borrowing the index, respectively. In particular, we assume these three variables to be constant, which is at least true on the short-term.</p> <p>By construction of the LETF, we thus have<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">9</a></sup> \(\begin{equation} \label{basic-ret} \frac{dL_t}{L_t}=\beta \frac{dS_t}{S_t} - (\beta-1)r dt - fdt + 1_{\beta&lt;0}\beta\lambda dt \end{equation}\) where the cost of borrowing the index $\beta\lambda dt$ is incurred only for inverse LETFs i.e. when $\beta&lt;0$.</p> <p>In order to move forward we now need a model for the daily index returns $\frac{dS_t}{S_t}$. We use an Itô process \(\begin{equation} \label{ito} \frac{dS_t}{S_t}=\mu_t dt + \sigma_t dW_t \end{equation}\)</p> <p>Plugging ($\ref{ito}$) in ($\ref{basic-ret}$) and separating the drift and noise terms, we obtain \(\begin{equation} \frac{dL_t}{L_t}=\big(\beta\mu_t-(\beta-1)r-f+1_{\beta&lt;0}\beta\lambda\big)dt + \beta\sigma_t dW_t \end{equation}\)</p> <p>We then use Itô’s lemma to find \(\begin{equation} d[\ln{L_t}]=\big(\beta\mu_t-(\beta-1)r-f+1_{\beta&lt;0}\beta\lambda - \frac{\beta^2 \sigma_t^2}{2}\big)dt + \beta\sigma_t dW_t \end{equation}\)</p> <p>Integrating from 0 to $T$ yields \(\begin{equation} \label{eq3} \ln \frac{L_T}{L_0} = \beta M_T - \big((\beta-1)r -f + 1_{\beta&lt;0}\beta\lambda\big)T - \frac{\beta^2}{2}V_T + \beta \sqrt{V_T}Z \end{equation}\) where $M_T=\int_0^T \mu_t dt$, $V_T=\int_0^T \sigma_t^2 dt$ and $Z=N(0,1)$.</p> <p>To simplify (\ref{eq3}), we remark that \(\begin{equation} \label{eq4} \ln \frac{S_T}{S_0} = M_T - \frac{V_T}{2} + \sqrt{V_T}Z \end{equation}\)</p> <p>Plugging (\ref{eq4}) in (\ref{eq3}), we obtain \(\begin{equation} \ln \frac{L_T}{L_0} = \beta \ln \frac{S_T}{S_0} + \frac{\beta-\beta^2}{2}V_T - \big((\beta-1)r -f + 1_{\beta&lt;0}\beta\lambda\big)T \end{equation}\)</p> <p>Finally, exponentiation yields \(\begin{equation} \frac{L_T}{L_0} = \bigg(\frac{S_T}{S_0}\bigg)^\beta \exp\bigg(\frac{\beta-\beta^2}{2}V_T - \big((\beta-1)r -f + 1_{\beta&lt;0}\beta\lambda\big)T\bigg) \end{equation}\)</p> <p>Neglecting $r, f, \lambda$, we end up with the following neat expression \(\begin{equation} \label{eq:final} \boxed{\frac{L_T}{L_0} = \bigg(\frac{S_T}{S_0}\bigg)^\beta \exp\bigg(-\frac{\beta^2-\beta}{2}V_T\bigg)} \end{equation}\)</p> <h3 id="interpretation-and-consequences">Interpretation and consequences</h3> <p>The first thing to note from ($\ref{eq:final}$) is that we clearly do not have the linear relationship $\frac{L_T}{L_0}-1=\beta(\frac{S_T}{S_0}-1)$ which we may naively expect. In fact, this linear relationship holds for the static portfolio only. Instead, we have a linear relationship between the <em>logarithms</em> of the LETF and the index, which is not the same thing at all! It means an <em>exponential</em> relationship between the LETF and the index, aka huge swings in the LETF’s value. This is the first reason why LETFs are not suitable for long-term investments.</p> <p>The second thing to note is the term $\exp\big(-\frac{\beta^2-\beta}{2}V_T\big)$ which is always strictly less than 1 since $\beta^2-\beta$ is positive for all the values of $\beta$ considered. Since $V_T=\int_0^T \sigma_t^2 dt$ is the realized volatility, we see that the LETF is adversely exposed to the index turbulence: there is a <strong>“volatility drag”</strong>. Thus, the higher the volatility, the larger $V_T$ and thus we need $\frac{S_T}{S_0}\gg 1$ to compensate. In particular, if we simply assume that $\forall t, \sigma_t=\sigma$, then $V_T=\sigma^2 T$ and thus $\frac{L_T}{L_0} = \bigg(\frac{S_T}{S_0}\bigg)^\beta \exp\bigg(-\frac{\beta^2-\beta}{2}\sigma^2 T\bigg)$ i.e. there is an exponential time decay in the long-term performance of the LETF.</p> <p>The bottom line is that LETFs are not adequate buy-and-hold investments for the two reasons above. Holding them for too long will not yield the hoped-for linear relationship $r_\text{total}^\text{LETF}=\beta \times r_\text{total}^\text{index}$ ; worse still, it will incur an inevitable volatility drag which scales more or less as an exponential time decay.</p> <h2 id="illustration-on-tqqq-and-sqqq">Illustration on TQQQ and SQQQ</h2> <p>Let’s illustrate the volatility decay of <code class="language-plaintext highlighter-rouge">TQQQ</code> and <code class="language-plaintext highlighter-rouge">SQQQ</code>, the 3x and -3x Nasdaq 100 LETFs respectively. We will use equation ($\ref{eq:final}$) to compute $-\frac{\beta^2-\beta}{2}V_T = \ln(\frac{L_T}{L_0})-\beta \ln(\frac{S_T}{S_0})$: we expect to find a negatively sloped line.</p> <div class="row justify-content-center" id="fig-2"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/leveraged_etf/tqqq-480.webp 480w,/assets/img/posts/leveraged_etf/tqqq-800.webp 800w,/assets/img/posts/leveraged_etf/tqqq-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/leveraged_etf/tqqq.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="tqqq" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/leveraged_etf/sqqq-480.webp 480w,/assets/img/posts/leveraged_etf/sqqq-800.webp 800w,/assets/img/posts/leveraged_etf/sqqq-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/leveraged_etf/sqqq.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="sqqq" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 2. Exponential decay of TQQQ and SQQQ. </div> <p><a href="#fig-2">Figure 2</a> presents the exponential decay of <code class="language-plaintext highlighter-rouge">TQQQ</code> and <code class="language-plaintext highlighter-rouge">SQQQ</code> over the past 15 years. We obtain a negatively sloped line as expected. In addition, we find that the slope is steeper for <code class="language-plaintext highlighter-rouge">SQQQ</code> than for <code class="language-plaintext highlighter-rouge">TQQQ</code>, which is consistent with the fact that the volatility drag is proportional to $\beta^2-\beta$, which is larger for <code class="language-plaintext highlighter-rouge">SQQQ</code> than for <code class="language-plaintext highlighter-rouge">TQQQ</code>. We cannot say much more about the slopes and the intersects since we’ve neglected $r, f, \lambda$ in our model.</p> <h2 id="conclusion">Conclusion</h2> <p>We’ve shown that LETFs are more complex than they seem. In particular, buying a $\beta$ LETF is not the same as buying a static portfolio with leverage $\beta$. Equation ($\ref{eq:final}$) nicely sums up the double problem with LETFs: 1) they vary exponentially with the underlying index 2) they incur a volatility drag. We could dig deeper by taking into account $r, f, \lambda$ in our model, but the main point is already clear: LETFs are not suitable for long-term investments.</p> <p>You may wonder: who uses LETFs then? I have no definite answer, but certainly traders who wish to hedge their positions with less collateral may find LETFs useful. In addition, LETFs can be used to speculate on short-term market movements. The average detention period of <code class="language-plaintext highlighter-rouge">TQQQ</code> (~3 days) and <code class="language-plaintext highlighter-rouge">SQQQ</code> (&lt;1 day) is a clear indication that LETFs are not meant to be held for long periods.</p> <p><strong>Footnotes &amp; References</strong>:</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:investopedia"> <p><em>A Brief History of Exchange-Traded Funds</em>. Simpson, S. <a href="investopedia.com/articles/exchangetradedfunds/12/brief-history-exchangetraded-funds.asp">Investopedia.com</a> <a href="#fnref:investopedia" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:ishares"> <p><em>Global ETF Market Facts: Three things to know from Q3 2023.</em>. Cohen, S. <a href="ishares.com/us/insights/global-etf-facts">iShares.com</a> <a href="#fnref:ishares" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:marketwatch"> <p><em>ProFunds prepares first leveraged ETFs</em>. Spence, J. <a href="marketwatch.com/story/profunds-readies-first-leveraged-etfs">MarketWatch.com</a> <a href="#fnref:marketwatch" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:sec"> <p><em>Updated Investor Bulletin: Leveraged and Inverse ETFs</em>. SEC Investor Alerts and Bulletins. <a href="sec.gov/resources-for-investors/investor-alertsbulletins/updated-investor-bulletin-leveraged-inverse-etfs">sec.gov</a> <a href="#fnref:sec" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:1"> <p>Such static portfolio is obtained by borrowing cash/stocks on day 0 to get the desired level of leverage and then holding until exit. In particular, there is no daily rebalancing and the portfolio’s value can be negative. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4"> <p>Note that formally, the static portfolio can reach negative AUM. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:avellaneda"> <p><em>Path-dependence of Leveraged ETF returns</em>. Avellaneda, M. <a href="#fnref:avellaneda" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>The Net Asset Value of a fund is the value of its assets divided by its number of shares outstanding. Technically, the NAV and the price per share are two distinct values, but in practice they remain very close for non-arbitrage reasons, and thus in this paper we will refer to LETF’s NAV or price interchangeably. In addition, we will always use split-adjusted NAVs/prices. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>Technically, this formula holds true for daily returns only i.e. when $dt=\Delta t=1$ day, but we will assume it to be true on an infinitesimal time scale. Note that Avellaneda also proposed a discrete-time model equivalent to the one described here. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><summary type="html"><![CDATA[TL;DR: Leveraged ETFs amplify daily returns, which is not the same as basic leverage, especially in the long term. Digging into the math reveals that leveraged ETFs are not suitable buy-and-hold investments as they 1) exhibit huge price swings 2) incur a volatility drag.]]></summary></entry></feed>