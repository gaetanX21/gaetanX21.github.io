<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Filtrations demystified | Gaëtan Ecrepont </title> <meta name="author" content="Gaëtan Ecrepont"> <meta name="description" content="TL;DR: Filtrations are a key ingredient in defining stochastic processes and modeling the accumulation of available information over time. Filtrations are also often poorly understood; this post aims to demystify them."> <meta name="keywords" content="portfolio-website, machine-learning, statistics, quantitative-finance"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%98%84%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://gaetanx21.github.io/blog/2025/filtrations/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Gaëtan</span> Ecrepont </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Filtrations demystified</h1> <p class="post-meta"> Created in October 05, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/probability-theory"> <i class="fa-solid fa-hashtag fa-sm"></i> probability-theory,</a>   <a href="/blog/tag/stochastic-processes"> <i class="fa-solid fa-hashtag fa-sm"></i> stochastic-processes</a> </p> </header> <article class="post-content"> <div id="markdown-content"> \[\newcommand{\R}{\mathbb{R}} \newcommand{\Q}{\mathbb{Q}} \newcommand{\N}{\mathbb{N}} \newcommand{\A}{\mathcal{A}} \newcommand{\P}{\mathbb{P}} \newcommand{\T}{\mathbb{T}} \newcommand{\F}{\mathcal{F}} \newcommand{\FF}{\mathbb{F}}\] <p>If you’ve ever studied stochastic processes<sup id="fnref:random-process"><a href="#fn:random-process" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> in a formal setting, you must have come across the concept of <em>filtration</em>. I remember my stochastic calculus course where the professor introduced filtrations in a very abstract way, which left me quite confused. He then added that “filtrations encode the information available at each time step”, which was a bit more intuitive but still quite vague. Anyway, this was how I understood filtrations for quite some time, until one day I decided to dig deeper into the topic and really understand what filtrations are and why they are useful. This post aims to share this understanding!</p> <p><strong>NB:</strong> I will assume that you are familiar with <em>σ-algebras</em>. If not, I recommend reading my previous post on <a href="/blog/2025/measurability/">measurability</a> before continuing!</p> <hr> <h2 id="i-motivation">I. Motivation</h2> <p>When dealing with basic random variables, we simply need:</p> <ol> <li>a probability space $(\Omega, \A, \P)$,</li> <li>a random variable $X: \Omega \to E$, where $(E, \mathcal{E})$ is another measurable space.</li> </ol> <p>This setup is sufficient for many applications in probability theory.</p> <p>However, defining stochastic processes requires a subtler formalism. The core reason is that stochastic processes are collections of random variables indexed by time<sup id="fnref:indexing"><a href="#fn:indexing" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>, and as such the information contained in the process accumulates over time, which must be accounted for in the formalism. Indeed, just like we need σ-algebras to define which events are measurable for a random variable $X$, we need a mathematical object to define which events are measurable <em>at a given time $t$</em> for a stochastic process $(X_t) _ {t\in\T}$. This mathematical object is called a <em>filtration</em>.</p> <h2 id="ii-defining-filtrations">II. Defining filtrations</h2> <h3 id="a-intuitive-definition">A. Intuitive definition</h3> <p>Before delving into the formal definition of filtrations, I think the <a href="https://en.wikipedia.org/wiki/Filtration_(probability_theory)" rel="external nofollow noopener" target="_blank">Wikipedia page</a> sums it up quite nicely:</p> <blockquote> <p>“In the theory of stochastic processes, a subdiscipline of probability theory, <strong>filtrations are totally ordered collections of subsets that are used to model the information that is available at a given point</strong> and therefore play an important role in the formalization of random (stochastic) processes.”</p> </blockquote> <h3 id="b-formal-definition">B. Formal definition</h3> <p>Formally, let $(\Omega, \A, \P)$ be a probability space and $\T$ be a totally ordered set (typically $\N$ or $\R_+$).</p> <p>A <em>filtration</em> is a family of sub-σ-algebras $(\F_t)_{t\in\T}$ of $\A$ such that for all $s, t \in \T$ with $s \leq t$, we have $\F_s \subseteq \F_t (\subseteq \A)$. In other words, the σ-algebras are nested and non-decreasing over time. We often denote a filtration with the symbol $\FF$.</p> <p>If $(\Omega, \A, \P)$ is a probability space and $\FF=(\F_t)_{t\in\T}$ is a filtration on this space, then the quadruplet $(\Omega, \A, \FF, \P)$ is called a <em>filtered probability space</em>.</p> <p>Importantly, note that we do not need stochastic processes to define filtrations. A filtration $\FF$ can be defined on any probability space, regardless of whether it is associated with a stochastic process or not. However, filtrations are almost always constructed in relation to a stochastic process, using what we call the <em>natural filtration</em> of the process.</p> <h3 id="c-natural-filtration">C. Natural filtration</h3> <p>Given a stochastic process $(X_t) _ {t\in\T}$, its natural filtration is defined as $\F_t = \sigma(X_s | s \leq t)$ for each $t \in \T$. In other words, $\F_t$ is the smallest σ-algebra that makes all random variables $X_s$ for $s \leq t$ measurable. Intuitively, $\F_t$ declares all the information about the process <strong>available</strong> at time $t$.</p> <h3 id="d-available-information--information">D. Available information ≠ information</h3> <p>I really want to emphasize the difference between <em>available information</em> and (actual) <em>information</em>, which is often the source of confusion when dealing with filtrations.</p> <p>Let’s consider a stochastic process $(X_t) _ {t\in\T}$ with its natural filtration $\FF=(\F_t)_{t\in\T}$.</p> <p>Interpreting $\F_t$ as containing the information $(X_s)_{s\leq t}$ is <strong>incorrect</strong>. That is, $\F_t$ <em>does not</em> contain the realized values of $X_s$ for $s \leq t$. If this isn’t clear, remark that —by construction— the σ-algebra $\F_t$ will be identical regardless of the specific values taken by the random variables $X_s$ for $s \leq t$; thus, it cannot possibly encode this information.<sup id="fnref:filtration-independent"><a href="#fn:filtration-independent" class="footnote" rel="footnote" role="doc-noteref">3</a></sup> Instead, $\F_t$ declares explicitly which information about the process is <strong>available</strong> at time $t$, without holding the information in itself!</p> <p>The key insight —which is not so straightforward in my opinion— is that being <em>measurable</em> with respect to $\F_t$ means being <em>determinable</em> using the information available at time $t$. In other words, if a random variable $Z$ is $\F_t$-measurable, then at time $t$ we will be able to determine its value. In particular, for any statement $S$ about the process, if $Y=\mathbf{1}_S$ is $\F_t$-measurable, then at time $t$ we will know with certainty whether $S$ is true or false. Once again, the information about the veracity of $S$ <em>is not</em> contained in $\F_t$; $\F_t$ simply declares that we will know if $S$ is true or false at time $t$.</p> <p>The above intuition can be formalized as follows:</p> <blockquote> <p>Consider a random process $(X_t) _ {t\in\T}$ and its natural filtration $\FF=(\F_t) _ {t\in\T}$. Let $t\in\T$ be a specific point in time, and $A\in\F_t$ a $\F_t$-measurable event. Consider $\omega\in\Omega$ an arbitrary realization. Then, at time $t$, we will know deterministically whether $\omega\in A$ or not.</p> </blockquote> <p>This is what it means when we say that $\F_t$ encodes the <em>available</em> information at time $t$.</p> <h2 id="iii-examples">III. Examples</h2> <p>At this point, you may still be a bit confused about what filtrations really are. A few examples should help clarify things!</p> <h3 id="a-coin-tosses">A. Coin tosses</h3> <p>Consider a sequence of two consecutive coin tosses, modeled by the stochastic process $(X_1, X_2)$ (i.e. $\T=\lbrace 1, 2\rbrace$) where $X_i$ is the outcome of the $i$-th toss ($H$ or $T$).</p> <ol> <li>The sample space is $\Omega = \lbrace HH, HT, TH, TT\rbrace$.</li> <li>The σ-algebra is $\A = \mathcal{P}(\Omega)$ (the power set of $\Omega$).</li> <li>The probability measure $\P$ assigns a probability of $1/4$ to each outcome.</li> </ol> <p>Now let’s think about the natural filtration $\FF$ of this process.</p> <ol> <li>At time $t=0$ (before any toss), we have $\F_0 = \big\lbrace\emptyset, \Omega\big\rbrace$, i.e. there is no information available whatsoever about the outcomes of the tosses.</li> <li>At time $t=1$ (after the first toss), we have $\F_1 = \sigma(X_1) = \big\lbrace\emptyset, \Omega, \lbrace HH, HT\rbrace, \lbrace TH, TT\rbrace\big\rbrace$, i.e. we now know the outcome of the first toss, but not the second. Indeed, after observing the first toss, we can distinguish between the events <em>“first toss is H”</em> ($\lbrace HH, HT\rbrace$) and <em>“first toss is T”</em> ($\lbrace TH, TT\rbrace$). In other words, we can tell whether our realization $\omega$ lies in $\lbrace HH, HT\rbrace$ or in $\lbrace TH, TT\rbrace$.</li> <li>At time $t=2$ (after the second toss), we have \(\begin{aligned} \F_2 &amp;=\sigma(X_1, X_2) \\ &amp;=\big\lbrace \emptyset, \Omega, \lbrace HH \rbrace, \lbrace HT \rbrace, \lbrace TH \rbrace, \lbrace TT \rbrace, \lbrace HH, HT \rbrace, \lbrace HH, TH \rbrace, \lbrace HH, TT \rbrace, \lbrace HT, TH \rbrace, \lbrace HT, TT \rbrace, \lbrace TH, TT \rbrace, \lbrace HH \rbrace^c, \lbrace HT \rbrace^c, \lbrace TH \rbrace^c, \lbrace TT \rbrace^c \big\rbrace \\ &amp;=\mathcal{P}(\Omega) \end{aligned}\)</li> </ol> <p>i.e. we know the outcomes of both tosses, so we can distinguish between all possible outcomes.</p> <h3 id="b-academic-outcomes">B. Academic outcomes</h3> <p>We can make a more concrete version of the previous example. Let’s consider a world in which students can go to two universities: Stanford ($S$) or Carnegie Mellon ($C$). After graduating, they can either get a job ($J$) or pursue a PhD ($P$). We can model this situation with a stochastic process $(X_1, X_2)$ where $X_1$ is the university attended and $X_2$ is the post-graduation outcome.</p> <p>The sample space is $\Omega = \lbrace SJ, SP, CJ, CP\rbrace$, the σ-algebra is $\A = \mathcal{P}(\Omega)$, and we can define a uniform probability measure $\P$ for simplicity.</p> <p>The filtration $\FF$ of this process is as follows:</p> <ol> <li>At time $t=0$ (before university), we have $\F_0 = \big\lbrace\emptyset, \Omega\big\rbrace$, i.e. there is no information available about the student’s academic outcome.</li> <li>At time $t=1$ (after university), we have $\F_1 = \sigma(X_1) = \big\lbrace\emptyset, \Omega, \lbrace SJ, SP\rbrace, \lbrace CJ, CP\rbrace\big\rbrace$, i.e. we now know which university the student attended, but not their post-graduation outcome.</li> <li>At time $t=2$ (after graduation), we have $\F_2 = \sigma(X_1, X_2) = \mathcal{P}(\Omega)$, i.e. we know the student’s entire academic outcome.</li> </ol> <h3 id="c-brownian-motion">C. Brownian motion</h3> <p>I’ll assume that you are familiar with Brownian motion. If not, check out the Wikipedia page on the <a href="https://en.wikipedia.org/wiki/Wiener_process" rel="external nofollow noopener" target="_blank">Wiener process</a>.</p> <p>For the one-dimensional Brownian motion $(B_t)_{t\geq 0}$:</p> <ol> <li>The sample space is $\Omega = \R^\T$<sup id="fnref:continuous-paths"><a href="#fn:continuous-paths" class="footnote" rel="footnote" role="doc-noteref">4</a></sup> with $\T = [0, +\infty)$.</li> <li>The σ-algebra is $\A = \sigma(B_t : t \geq 0)$ (the σ-algebra generated by the Brownian motion).</li> <li>The probability measure $\P$ is (by definition) the Wiener measure.</li> </ol> <p>Unlike the previous examples, $(B_t) _ {t\geq 0}$ is a <em>continuous-time</em> stochastic process, so we cannot explicitly write down the filtration $\FF=(\F_t)_{t\geq 0}$, except for $\F_0 = \lbrace\emptyset, \Omega\rbrace$. However, $\F_t$ still represents the information available about the Brownian motion up to time $t$. For instance, the event $A = (B_1 &gt; 0)$ is such that:</p> <ol> <li>$A \notin \F_t$ for all $t &lt; 1$ i.e. before time $t=1$ we cannot know whether $B_1$ is positive or not</li> <li>$A \in \F_t$ for all $t \geq 1$ i.e. at time $t=1$ and afterwards we can know for sure whether $B_1$ is positive or not.</li> </ol> <p>Although it’s somewhat less straightforward to describe what filtrations look like for continuous-time processes, the key idea remains the same: $\F_t$ encodes all the information that <em>can be known for sure</em> about the process at time $t$.</p> <h2 id="conclusion">Conclusion</h2> <p>I’ve tried to make this post as intuitive as possible, and hopefully the examples helped in that regard. Filtrations do not need to be complicated, they are simply a way to formalize the idea of accumulating <strong>available</strong> information over time in the context of stochastic processes. Yes, you can live without knowing the full truth behind filtrations, but beyond a certain point, it’s worth deeply understanding the mathematical objects you manipulate.</p> <p>In machine learning, many people use quite complicated models without really grasping the underlying mathematics<sup id="fnref:diffusion"><a href="#fn:diffusion" class="footnote" rel="footnote" role="doc-noteref">5</a></sup>. Of course, this is fine to a certain extent, but I firmly believe that having an intuitive understanding of the theory is key whenever you want to venture <em>just a tiny bit</em> off the beaten path.</p> <p>Finally, I must mention that filtrations exist outside the realm of probability theory. In essence, given a set $X$, any family of nested subsets of $X$ is a filtration; in particular, these subsets <em>do not</em> need to be σ-algebras. One typical use case in linear algebra is to simplify the study an infinite-dimensional vector space $V$ by instead considering an increasing sequence $(V_t) _ {t\in\N}$ of finite-dimensional vector spaces such that $\bigcup_{t\in\N} V_t = V$. This is called a <em>filtration of $V$</em>.</p> <hr> <p><strong>References</strong>:</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:random-process"> <p>Stochastic processes are equivalently called random processes in some literature. <a href="#fnref:random-process" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:indexing"> <p>More precisely, the index $\T$ can be any totally ordered set, but in most cases we have $\T=\N$ or $\T=\R_+$ which are interpreted as discrete and continuous time respectively. <a href="#fnref:indexing" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:filtration-independent"> <p>Another way to put it is that the filtration $\FF$ is defined purely in terms of the σ-algebras generated by the random variables $(X_t) _ {t\in\T}$, and not their realizations. Thus, $\FF$ is independent of the specific outcome $\omega\in\Omega$. This clearly shows that $\F_t$ cannot contain the actual information about the values taken by $(X_s) _ {s\leq t}$. <a href="#fnref:filtration-independent" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:continuous-paths"> <p>In practice, one can prove that the sample paths $B(\omega,\cdot): t \mapsto B(\omega,t)$ are almost surely continuous, so we could restrict $\Omega$ to $\mathcal{C}(\T,\R)$ without loss of generality. <a href="#fnref:continuous-paths" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:diffusion"> <p>For instance, it’s easy to overlook that diffusion modeling amounts to solving a time-reversed stochastic differential equation, yet seeing diffusion under the light of SDEs yields <a href="https://yang-song.net/blog/2021/score/" rel="external nofollow noopener" target="_blank">fruitful insights</a>. <a href="#fnref:diffusion" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Gaëtan Ecrepont. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-X0M5D3J28G"></script> <script defer src="/assets/js/google-analytics-setup.js?9d15c8cd8e550d35a6c2d883f01c70c4"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> </body> </html>